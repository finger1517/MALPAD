# Tech
Prefill and Decoding Disaggregation (PD Disaggregation):
1. Prefill: Generate the first token based on the input token sequence
2. Decoding: Each token computation involves both KV-Cache read and store operations, though with significantly less computation compared to the prefill phase

# Thinking
- Without publicity, there is no occurrence; without expression, there is no thinking

## Why Use Ray?
1. OpenAI: Ray is a robust module for distributed computing; when distributed computing tasks are needed, Ray is essential
2. LinkedIn: Ray provides scheduling for online services. Ray.Serving breaks down the inference graph into atomic layers and optimizes CPU & GPU hybrid computing scenarios
3. Adobe & Niantic: Offers flexibility, scalability, and extensibility. Ray reduces scheduling coding time by 85%
4. Spotify: Uses Ray + PyTorch to package their MLOps SDK
5. Pinterest: Data Processing Framework
   - Before: Used multiprocessing PyTorch DataLoader for GPU nodes with limitations:
     - Monolithic architecture with limited scalability
     - CPU and GPU computing on same nodes, preventing efficient heterogeneous computing
   - After: Implemented Ray.Dataset for data preprocessing + Ray.Trainer + Ray.Serve
6. Uber: Uses Ray to set up distributed process groups
   - Uses NCCL and PyTorch as basic framework; DeepSpeed + Hugging Face for training SOTA LLMs
   - Employs Ray.Torch trainer for scheduling and orchestrating the training process
7. Ant Group: Ray ecosystem running on 150 CPU cores
8. Ray's enterprise adoption rate is rapidly increasing. Beyond OpenAI, international tech giants (Google, AWS, Microsoft, Meta) are actively embracing Ray. Traditional enterprises (Adobe, VMware, IBM) and hardware manufacturers (NVIDIA, Intel) are integrating into Ray's ecosystem. Chinese companies like Ant Group, NetEase, ByteDance, and Huawei are continuously developing on Ray. Additionally, many well-known startups have chosen Ray, including Yang Qing, former Alibaba Cloud computing platform lead, who integrated Ray into their latest open-source project Lepton AI for distributed computing implementation.
9. Distributed Agent SDK: Leverages Ray's concepts for actor and task registration. Enables easy implementation of RAG-agent and Multi-agent systems. Future development may include Agent protocol to unify agent frameworks and advance Online-Offline unified agent frameworks for real-world applications.

Our Design Goals:
1. Easy to use, deploy, and scale
2. Optimize CPU and GPU utilization

## Learning Goals for This Month
1. Master video processing operators and their practical applications
2. Implement test-driven development (TDD) practices to enhance code quality
