1. openai
2. anthropic
3. grok
4. google-gemini
5. deepseek
6. meta-llama
7. qwen
8. doubao-seed





## OpenAI 
- Reasoning
    - MMLU (Massive Multitask Language Understanding) 
    - GPQA (Graduate-Level Google-Proof Q&A)
    - GPT-4.1 reportedly setting a new standard by exceeding 90% accuracy
- coding and engineering capabilities
    - swe-bench verified: human-validated subset evaluating real-world software engineering tasks
    - swe-lancer: end-to-end coding assessment with financial scoring metrics
- instruction following and agency
    - internal API instruction following(with "hard" variants)
    - multiChallenge
    - COLLIE
    - IFEVAL
    - Multi-IF
- Long-Context Evaluation
    - OpenAI-MRCR: testing with 128K and 1M token contexts
    - Graphwalks bfs and Graphwalks parents: for structured reasoning in long contexts ( Graphwalks‚Å†(opens in a new window), a dataset for evaluating multi-hop long-context reasoning)
- MM Capabilities
    - MMMU
    - MathVista
    - CharXiv-R and CharXiv-D

- Function Calling
    - complexFuncBench
    - Taubench airline; Taubench retail


## Anthropic
- core capability Benchmarks
    - MMLU
    - GPQA
    - MMMU
- Coding
    - HumanEval
    - APPS
    - MBPP
    - SWE-bench
- specialized reasoning
    - WinoGrande: for common-sense reasoning
    - RACE-H: fro reading comprehension
    - BIG-Bench-Hard: Fro a variety of challenging tasks
- Domain-Specific Excellence
    - S&P AI Benchmarks by Kensho(business and financial domain)(close source)
    - BizBench: A Quantitative Reasoning Benchmark for Business and Finance. [bizbench](https://arxiv.org/abs/2311.06602)

## Grok
- comprehensive intelligence assessment
    - MMLU-Pro
    - GPQA-Diamond
    - Humanity's Last Exam
    - MATH-500

- Math
    - AIME
    - LiveCodeBench
    - SciCode

- community-based evaluation
    - LMArena

# Gemini

- reasoning and knowledge
    - Humanity's Last Exam
    - GPQA Diamond

- Math
    - AIME 2024
    - AIME 2025

- Coding and Engineering
    - livecodebench
    - aider polyglot
    - swe-bench verified

- long-context and multimodal
    - mrcr
    - mmmu


## DeepSeek
- Knowledge Assessment
    - MMLU
    - MMLU-Pro
    - GPQA
- Factual Knowledge
    - sampleQA
    - Chinese SimpleQA

- Math


# Meta-LLama
- logic reasoning
    - arc-agi
- math
    - beyong AIME



